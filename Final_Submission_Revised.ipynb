{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "87a85b04bf9f407fbe976d0cb4f44021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67fb9b8bf4f64889a701af2e6668bd39",
              "IPY_MODEL_1ec9c1d0a6254079b3d4837867c779f1",
              "IPY_MODEL_d9a6d425f51a46ffa74e5869ac7e69a0"
            ],
            "layout": "IPY_MODEL_50596aa584b049dca8e2493b3014b1b1"
          }
        },
        "67fb9b8bf4f64889a701af2e6668bd39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1682daacd2f9494c91af84579aa50a90",
            "placeholder": "​",
            "style": "IPY_MODEL_25a4c19134494f65b5502eb8b33f130f",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "1ec9c1d0a6254079b3d4837867c779f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96d3cad14a1b41d7a52db5a054a5335a",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a514cfed85874cf0973c22a0cab92a5f",
            "value": 6
          }
        },
        "d9a6d425f51a46ffa74e5869ac7e69a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecc078d34f4142e9a5b34175539b7953",
            "placeholder": "​",
            "style": "IPY_MODEL_11147eb24b3044e498e7518a136627a9",
            "value": " 6/6 [00:16&lt;00:00,  2.10s/it]"
          }
        },
        "50596aa584b049dca8e2493b3014b1b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1682daacd2f9494c91af84579aa50a90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25a4c19134494f65b5502eb8b33f130f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96d3cad14a1b41d7a52db5a054a5335a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a514cfed85874cf0973c22a0cab92a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecc078d34f4142e9a5b34175539b7953": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11147eb24b3044e498e7518a136627a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "343bc7fa4e4f4e8c861976625f522f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2677bf345c64113a7bafaa9b9ef2fc2",
              "IPY_MODEL_825a729413324dc994771e0a7f1899e3",
              "IPY_MODEL_95d0752e42b24ed1ba27eec281d55a39"
            ],
            "layout": "IPY_MODEL_77fb0c96ca81469aa975f6a44b6a24bb"
          }
        },
        "a2677bf345c64113a7bafaa9b9ef2fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_221a797f342f4f1696617d9755201d08",
            "placeholder": "​",
            "style": "IPY_MODEL_259a355eb2fe4a72bf2526e41eb1f690",
            "value": "100%"
          }
        },
        "825a729413324dc994771e0a7f1899e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23dc9ea18c094bc585efe9346300ed4b",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b35769e5ab0c49f6969eab6d04b327e1",
            "value": 50
          }
        },
        "95d0752e42b24ed1ba27eec281d55a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e49294ec73f41e59f7f294d33ba782f",
            "placeholder": "​",
            "style": "IPY_MODEL_ce1fed5397cf4af28af56a762b1a82c3",
            "value": " 50/50 [00:09&lt;00:00,  7.06it/s]"
          }
        },
        "77fb0c96ca81469aa975f6a44b6a24bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "221a797f342f4f1696617d9755201d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "259a355eb2fe4a72bf2526e41eb1f690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23dc9ea18c094bc585efe9346300ed4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b35769e5ab0c49f6969eab6d04b327e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e49294ec73f41e59f7f294d33ba782f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce1fed5397cf4af28af56a762b1a82c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dynamic Style Visualizer Code\n",
        "The presented code works best as described on Google Colab, to make it work on local environments, we might need to setup NVIDIA CUDA drivers sepparately and add additional checks to make sure that our code recognizes the NVIDIA GPU's."
      ],
      "metadata": {
        "id": "QfSFznivRxoz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "First install all the dependencies by running the cell below and it might ask you to restart the session, so please do so. After we have restarted the session, leaving the cell of installing packages, run the remaining code cells to get the desired output."
      ],
      "metadata": {
        "id": "1sk0ZZ1wR7j-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies with version control\n",
        "!pip install tensorflow==2.12.0 tensorflow-hub gradio diffusers transformers accelerate nltk sentence-transformers"
      ],
      "metadata": {
        "id": "DfKJkzAIR4_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4c04734-de38-4340-dcc3-aedf9e8ee18a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.12.0 in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.11/dist-packages (0.16.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.20.0)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.32.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (25.2.10)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.70.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.12.1)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12.0) (0.37.1)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub) (2.15.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.11)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.7.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.7.2)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.2->gradio) (14.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.5.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu124)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.45.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the NLP aspect of the code working we needed proper implementation of NLTK data, and ensure that all of them downloads properly because while implementing the NLP aspect, many a times we got some error regarding missing package due to which the emotion recognition was unable to work."
      ],
      "metadata": {
        "id": "fFg7RMENSWlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure NLTK properly with improved error handling\n",
        "import nltk\n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
        "import os\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger('DynamicStyleVisualizer')\n",
        "\n",
        "# Setup NLTK data path\n",
        "nltk_data_path = '/content/nltk_data'\n",
        "os.makedirs(nltk_data_path, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    nltk.download('punkt', download_dir=nltk_data_path)\n",
        "    nltk.download('averaged_perceptron_tagger', download_dir=nltk_data_path)\n",
        "    nltk.download('wordnet', download_dir=nltk_data_path)\n",
        "    nltk.download('omw-1.4', download_dir=nltk_data_path)\n",
        "    nltk.data.path.append(nltk_data_path)\n",
        "    logger.info(\"NLTK data downloaded successfully\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"Failed to download NLTK data: {str(e)}\")\n",
        "\n",
        "# Create a custom sentence tokenizer that doesn't rely on punkt_tab\n",
        "def custom_sent_tokenize(text):\n",
        "    \"\"\"Custom sentence tokenizer that uses PunktSentenceTokenizer directly\"\"\"\n",
        "    try:\n",
        "        # Initialize the tokenizer without loading from punkt_tab\n",
        "        tokenizer = PunktSentenceTokenizer()\n",
        "        return tokenizer.tokenize(text)\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Sentence tokenization failed: {str(e)}\")\n",
        "        # Fallback to simple split by period if tokenizer fails\n",
        "        return [s.strip() + \".\" for s in text.split(\".\") if s.strip()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhudXIg8ey7f",
        "outputId": "43604eba-c031-4584-f1d9-93100b82f965"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /content/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /content/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /content/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /content/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import re\n",
        "import functools\n",
        "\n",
        "# Import new NLP components\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "Oaa0Hv72e3B4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Manager Class for Modularity\n",
        "class ModelManager:\n",
        "    def __init__(self):\n",
        "        self.device = self._setup_device()\n",
        "        self.sd_pipe = None\n",
        "        self.stylize_fn = None\n",
        "        self.style_encoder = None\n",
        "        self.emotion_classifier = None\n",
        "        self.models_loaded = False\n",
        "\n",
        "    def _setup_device(self):\n",
        "        \"\"\"Configure GPU with fallback to CPU\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            logger.info(\"GPU is available. Using CUDA.\")\n",
        "            device = torch.device(\"cuda\")\n",
        "            torch.backends.cudnn.benchmark = True\n",
        "        else:\n",
        "            logger.info(\"GPU not available. Falling back to CPU.\")\n",
        "            device = torch.device(\"cpu\")\n",
        "        return device\n",
        "\n",
        "    def load_models(self):\n",
        "        \"\"\"Load all required models with proper error handling\"\"\"\n",
        "        if self.models_loaded:\n",
        "            logger.info(\"Models already loaded\")\n",
        "            return True\n",
        "\n",
        "        try:\n",
        "            # Stable Diffusion with appropriate settings based on device\n",
        "            logger.info(\"Loading Stable Diffusion model...\")\n",
        "            if self.device.type == \"cuda\":\n",
        "                self.sd_pipe = StableDiffusionPipeline.from_pretrained(\n",
        "                    \"stabilityai/stable-diffusion-2-1\",\n",
        "                    torch_dtype=torch.float16,\n",
        "                    safety_checker=None\n",
        "                ).to(self.device)\n",
        "            else:\n",
        "                # CPU-optimized settings\n",
        "                self.sd_pipe = StableDiffusionPipeline.from_pretrained(\n",
        "                    \"stabilityai/stable-diffusion-2-1\",\n",
        "                    safety_checker=None\n",
        "                ).to(self.device)\n",
        "                logger.info(\"Using CPU for Stable Diffusion. Processing will be slower.\")\n",
        "\n",
        "            # Style Transfer\n",
        "            logger.info(\"Loading style transfer model...\")\n",
        "            hub_module = hub.load('https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2')\n",
        "            self.stylize_fn = hub_module.signatures['serving_default']\n",
        "\n",
        "            # NLP Models\n",
        "            logger.info(\"Loading NLP models...\")\n",
        "            self.style_encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "            self.emotion_classifier = pipeline(\n",
        "                \"text-classification\",\n",
        "                model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
        "                return_all_scores=True,\n",
        "                device=0 if self.device.type == \"cuda\" else -1  # Use GPU if available\n",
        "            )\n",
        "\n",
        "            self.models_loaded = True\n",
        "            logger.info(\"All models loaded successfully\")\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to load models: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "# Initialize the model manager\n",
        "model_manager = ModelManager()\n"
      ],
      "metadata": {
        "id": "VOHu876Re6Ix"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Style configuration with enhanced metadata\n",
        "STYLE_MAPPING = {\n",
        "    'dreamy': {\n",
        "        'url': 'https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/1024px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg',\n",
        "        'keywords': ['peaceful', 'golden', 'serene', 'tranquil', 'calm', 'mystical', 'ethereal'],\n",
        "        'description': \"Serene, ethereal scenes with soft lighting and dreamy atmosphere\"\n",
        "    },\n",
        "    'dark': {\n",
        "        'url': 'https://upload.wikimedia.org/wikipedia/commons/c/c5/Edvard_Munch%2C_1893%2C_The_Scream%2C_oil%2C_tempera_and_pastel_on_cardboard%2C_91_x_73_cm%2C_National_Gallery_of_Norway.jpg',\n",
        "        'keywords': ['dark', 'stormy', 'shadow', 'gloomy', 'frightening', 'ominous', 'tense'],\n",
        "        'description': \"Dramatic, ominous scenes with shadows and emotional intensity\"\n",
        "    },\n",
        "    'vibrant': {\n",
        "        'url': 'https://upload.wikimedia.org/wikipedia/commons/b/b4/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg',\n",
        "        'keywords': ['bright', 'colorful', 'lively', 'energetic', 'vivid', 'festive', 'dynamic'],\n",
        "        'description': \"Colorful, energetic scenes with vivid details and dynamic composition\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Emotion to style mapping\n",
        "EMOTION_PRIORITY = {\n",
        "    'neutral': 'dreamy',\n",
        "    'fear': 'dark',\n",
        "    'sadness': 'dark',\n",
        "    'joy': 'vibrant',\n",
        "    'surprise': 'dreamy',\n",
        "    'anger': 'dark',\n",
        "    'disgust': 'dark',\n",
        "    'love': 'vibrant',\n",
        "    'confusion': 'dreamy',\n",
        "    'anticipation': 'vibrant'\n",
        "}\n",
        "\n",
        "# Default style to use if analysis fails\n",
        "DEFAULT_STYLE = 'vibrant'"
      ],
      "metadata": {
        "id": "5Jp8V-Ote8YB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@functools.lru_cache(maxsize=None)\n",
        "def load_style_image(style_url):\n",
        "    \"\"\"Load and preprocess style image to 256x256\"\"\"\n",
        "    try:\n",
        "        image_path = tf.keras.utils.get_file(os.path.basename(style_url)[-128:], style_url)\n",
        "        img = tf.io.decode_image(tf.io.read_file(image_path), channels=3, dtype=tf.float32)[tf.newaxis, ...]\n",
        "        img = tf.image.resize(img, (256, 256))\n",
        "        return tf.nn.avg_pool(img, ksize=[3,3], strides=[1,1], padding='SAME')\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to load style image: {str(e)}\")\n",
        "        # Return a default colored image if loading fails\n",
        "        return tf.ones([1, 256, 256, 3], dtype=tf.float32) * 0.5  # Gray image"
      ],
      "metadata": {
        "id": "MCs-qDMRe-BS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_mood_enhanced(text):\n",
        "    \"\"\"Enhanced mood detection using both keyword analysis and ML models\"\"\"\n",
        "    # Initial values\n",
        "    keyword_scores = {mood: 0 for mood in STYLE_MAPPING.keys()}\n",
        "    emotion_style = DEFAULT_STYLE\n",
        "    emotion_confidence = 0.0\n",
        "    semantic_style = DEFAULT_STYLE\n",
        "    semantic_confidence = 0.0\n",
        "\n",
        "    try:\n",
        "        # Legacy keyword-based analysis\n",
        "        text_lower = text.lower()\n",
        "        keyword_scores = {mood: sum(1 for kw in data['keywords'] if kw in text_lower)\n",
        "                         for mood, data in STYLE_MAPPING.items()}\n",
        "        logger.debug(f\"Keyword analysis results: {keyword_scores}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Keyword analysis failed: {str(e)}\")\n",
        "\n",
        "    # Emotion-based analysis\n",
        "    try:\n",
        "        if model_manager.emotion_classifier is not None:\n",
        "            emotion_results = model_manager.emotion_classifier(text)[0]\n",
        "            dominant_emotion = max(emotion_results, key=lambda x: x['score'])\n",
        "            emotion_style = EMOTION_PRIORITY.get(dominant_emotion['label'], DEFAULT_STYLE)\n",
        "            emotion_confidence = dominant_emotion['score']\n",
        "            logger.debug(f\"Emotion analysis: {dominant_emotion['label']} with confidence {emotion_confidence}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Emotion analysis failed: {str(e)}\")\n",
        "\n",
        "    # Semantic similarity analysis\n",
        "    similarities = {style: 0.0 for style in STYLE_MAPPING.keys()}\n",
        "    try:\n",
        "        if model_manager.style_encoder is not None:\n",
        "            text_embedding = model_manager.style_encoder.encode(text)\n",
        "            style_embeddings = {\n",
        "                style: model_manager.style_encoder.encode(data['description'])\n",
        "                for style, data in STYLE_MAPPING.items()\n",
        "            }\n",
        "            similarities = {\n",
        "                style: float(np.dot(text_embedding, style_emb) /\n",
        "                      (np.linalg.norm(text_embedding) * np.linalg.norm(style_emb)))\n",
        "                for style, style_emb in style_embeddings.items()\n",
        "            }\n",
        "            semantic_style = max(similarities, key=similarities.get)\n",
        "            semantic_confidence = similarities[semantic_style]\n",
        "            logger.debug(f\"Semantic analysis: {semantic_style} with confidence {semantic_confidence}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Semantic analysis failed: {str(e)}\")\n",
        "\n",
        "    # Combine analyses with weights\n",
        "    try:\n",
        "        combined_scores = {}\n",
        "        for style in STYLE_MAPPING.keys():\n",
        "            combined_scores[style] = (\n",
        "                (0.2 * keyword_scores.get(style, 0)) +\n",
        "                (0.4 * (1.0 if style == emotion_style else 0.0) * emotion_confidence) +\n",
        "                (0.4 * similarities.get(style, 0.0))\n",
        "            )\n",
        "\n",
        "        best_mood = max(combined_scores, key=combined_scores.get)\n",
        "        logger.info(f\"Selected mood: {best_mood} with score {combined_scores[best_mood]}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Mood combination failed: {str(e)}\")\n",
        "        best_mood = DEFAULT_STYLE\n",
        "\n",
        "    # Extract matched keywords for debugging\n",
        "    matched_keywords = []\n",
        "    try:\n",
        "        matched_keywords = [kw for kw in STYLE_MAPPING[best_mood]['keywords'] if kw in text_lower]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Return additional analysis details for debugging\n",
        "    analysis_details = {\n",
        "        'keyword_match': keyword_scores,\n",
        "        'emotion_analysis': {'style': emotion_style, 'confidence': emotion_confidence},\n",
        "        'semantic_analysis': {'style': semantic_style, 'confidence': semantic_confidence},\n",
        "        'combined_scores': combined_scores\n",
        "    }\n",
        "\n",
        "    return best_mood, matched_keywords, analysis_details"
      ],
      "metadata": {
        "id": "xjyNFiJGe_xL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_content_image(prompt):\n",
        "    \"\"\"Generate base image using Stable Diffusion with detailed prompts\"\"\"\n",
        "    try:\n",
        "        if model_manager.sd_pipe is None:\n",
        "            logger.error(\"Stable Diffusion model not loaded\")\n",
        "            return Image.new('RGB', (512, 512), color='gray')\n",
        "\n",
        "        detailed_prompt = f\"{prompt}, highly detailed, realistic, cinematic lighting\"\n",
        "        logger.info(f\"Generating image for prompt: {detailed_prompt[:50]}...\")\n",
        "\n",
        "        # Adjust settings based on device\n",
        "        steps = 50 if model_manager.device.type == \"cuda\" else 25  # Fewer steps on CPU\n",
        "\n",
        "        with torch.autocast(model_manager.device.type):\n",
        "            result = model_manager.sd_pipe(\n",
        "                detailed_prompt,\n",
        "                guidance_scale=7.5,\n",
        "                height=512,\n",
        "                width=512,\n",
        "                num_inference_steps=steps\n",
        "            )\n",
        "\n",
        "        logger.info(\"Image generation completed successfully\")\n",
        "        return result.images[0]\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Image generation failed: {str(e)}\")\n",
        "        # Return gray image with error text\n",
        "        from PIL import ImageDraw\n",
        "        img = Image.new('RGB', (512, 512), color='gray')\n",
        "        draw = ImageDraw.Draw(img)\n",
        "        draw.text((10, 10), f\"Generation Error: {str(e)[:100]}\", fill=\"white\")\n",
        "        return img"
      ],
      "metadata": {
        "id": "5fkG6XsmfBv9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== IMAGE PROCESSING FUNCTIONS ==========\n",
        "def process_scene(scene_text, style_image, mood, keywords, analysis_details=None):\n",
        "    \"\"\"Process individual scene through full pipeline with debugging details\"\"\"\n",
        "    try:\n",
        "        # Generate content image\n",
        "        content_image = generate_content_image(scene_text)\n",
        "\n",
        "        # Convert content image to TensorFlow tensor\n",
        "        content_tensor = tf.image.resize(\n",
        "            tf.keras.preprocessing.image.img_to_array(content_image)[tf.newaxis, ...] / 255.0,\n",
        "            (256, 256)\n",
        "        )\n",
        "\n",
        "        # Apply Neural Style Transfer\n",
        "        if model_manager.stylize_fn is None:\n",
        "            logger.error(\"Style transfer model not loaded\")\n",
        "            styled_image = content_image\n",
        "        else:\n",
        "            try:\n",
        "                outputs = model_manager.stylize_fn(\n",
        "                    placeholder=content_tensor,\n",
        "                    placeholder_1=style_image\n",
        "                )\n",
        "\n",
        "                # Convert styled output to PIL Image\n",
        "                styled_array = (np.clip(outputs['output_0'].numpy()[0], 0, 1) * 255).astype(np.uint8)\n",
        "                styled_image = Image.fromarray(styled_array)\n",
        "                logger.info(\"Style transfer completed successfully\")\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Style transfer failed: {str(e)}\")\n",
        "                styled_image = content_image  # Fall back to content image if style transfer fails\n",
        "\n",
        "        # Return all debugging details\n",
        "        return {\n",
        "            \"source_image\": content_image,\n",
        "            \"styled_image\": styled_image,\n",
        "            \"style_applied\": mood,\n",
        "            \"keywords_used\": keywords,\n",
        "            \"scene_text\": scene_text[:100]+\"...\" if len(scene_text) > 100 else scene_text,\n",
        "            \"analysis_details\": analysis_details\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Scene processing failed: {str(e)}\")\n",
        "        error_image = Image.new('RGB', (512, 512), color='red')\n",
        "        return {\n",
        "            \"source_image\": error_image,\n",
        "            \"styled_image\": error_image,\n",
        "            \"style_applied\": \"error\",\n",
        "            \"keywords_used\": [],\n",
        "            \"scene_text\": scene_text[:50]+\"...\" if len(scene_text) > 50 else scene_text,\n",
        "            \"analysis_details\": {\"error\": str(e)}\n",
        "        }"
      ],
      "metadata": {
        "id": "iNJqBGnUfDQy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_story(story_text):\n",
        "    \"\"\"Main processing pipeline with enhanced NLP analysis\"\"\"\n",
        "    logger.info(\"Processing story...\")\n",
        "\n",
        "    # Ensure models are loaded\n",
        "    if not model_manager.models_loaded:\n",
        "        success = model_manager.load_models()\n",
        "        if not success:\n",
        "            logger.error(\"Failed to load required models\")\n",
        "            return [{\"error\": \"Failed to load models\"}]\n",
        "\n",
        "    outputs = []\n",
        "\n",
        "    try:\n",
        "        # Use our custom sentence tokenizer\n",
        "        scenes = custom_sent_tokenize(story_text)\n",
        "        logger.info(f\"Story split into {len(scenes)} scenes\")\n",
        "\n",
        "        for i, scene in enumerate(scenes):\n",
        "            if len(scene.strip()) < 5:\n",
        "                logger.info(f\"Skipping scene {i+1}: too short\")\n",
        "                continue\n",
        "\n",
        "            logger.info(f\"Processing scene {i+1}/{len(scenes)}\")\n",
        "\n",
        "            # Analyze mood with enhanced NLP approach\n",
        "            mood, keywords, analysis_details = analyze_mood_enhanced(scene)\n",
        "\n",
        "            # Load style image based on mood\n",
        "            style_url = STYLE_MAPPING[mood]['url']\n",
        "            style_image = load_style_image(style_url)\n",
        "\n",
        "            # Process scene and collect all details\n",
        "            scene_details = process_scene(scene, style_image, mood, keywords, analysis_details)\n",
        "            outputs.append(scene_details)\n",
        "\n",
        "        logger.info(f\"Story processing completed: {len(outputs)} images generated\")\n",
        "        return outputs\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Story processing failed: {str(e)}\")\n",
        "        error_details = {\n",
        "            \"source_image\": Image.new('RGB', (512, 512), color='red'),\n",
        "            \"styled_image\": Image.new('RGB', (512, 512), color='red'),\n",
        "            \"style_applied\": \"error\",\n",
        "            \"keywords_used\": [],\n",
        "            \"scene_text\": \"Processing error\",\n",
        "            \"analysis_details\": {\"error\": str(e)}\n",
        "        }\n",
        "        return [error_details]"
      ],
      "metadata": {
        "id": "wCWuebxFfE_7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio Interface\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as app:\n",
        "    gr.Markdown(\"# 📖 Dynamic Story Visualizer with Enhanced NLP\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            story_input = gr.Textbox(\n",
        "                label=\"Your Story\",\n",
        "                placeholder=\"Once upon a time in a peaceful forest...\",\n",
        "                lines=5\n",
        "            )\n",
        "        with gr.Column(scale=1):\n",
        "            generate_btn = gr.Button(\"Generate Visual Story 🎨\", variant=\"primary\")\n",
        "            status = gr.Textbox(label=\"Status\", value=\"Ready\")\n",
        "            device_info = gr.Textbox(\n",
        "                label=\"Device Info\",\n",
        "                value=f\"Using {'GPU (CUDA)' if torch.cuda.is_available() else 'CPU'}\"\n",
        "            )\n",
        "\n",
        "    with gr.Row():\n",
        "        source_gallery = gr.Gallery(label=\"Source Images\", columns=3, object_fit=\"contain\")\n",
        "        styled_gallery = gr.Gallery(label=\"Stylized Images\", columns=3, object_fit=\"contain\")\n",
        "\n",
        "    with gr.Row():\n",
        "        style_info = gr.Textbox(label=\"Style Analysis Details\", lines=10)\n",
        "\n",
        "    def wrapper_fn(story_text):\n",
        "        if not story_text or len(story_text.strip()) < 10:\n",
        "            return [[], [], \"Please enter a longer story\", \"Error: Story too short\"]\n",
        "\n",
        "        try:\n",
        "            yield [[], [], \"\", \"Starting processing...\"]\n",
        "\n",
        "            # Load models if not already loaded\n",
        "            if not model_manager.models_loaded:\n",
        "                yield [[], [], \"\", \"Loading models...\"]\n",
        "                success = model_manager.load_models()\n",
        "                if not success:\n",
        "                    yield [[], [], \"\", \"Failed to load models. Please try again.\"]\n",
        "                    return\n",
        "\n",
        "            # Process the story\n",
        "            scenes_details = process_story(story_text)\n",
        "\n",
        "            if not scenes_details or \"error\" in scenes_details[0]:\n",
        "                yield [[], [], \"\", f\"Error: {scenes_details[0].get('error', 'Unknown error')}\"]\n",
        "                return\n",
        "\n",
        "            source_images = []\n",
        "            styled_images = []\n",
        "            style_details = []\n",
        "\n",
        "            for detail in scenes_details:\n",
        "                try:\n",
        "                    source_caption = f\"Source: {detail['scene_text']}\"\n",
        "                    styled_caption = f\"Styled ({detail['style_applied']}): {detail['scene_text']}\"\n",
        "\n",
        "                    source_images.append((detail[\"source_image\"], source_caption))\n",
        "                    styled_images.append((detail[\"styled_image\"], styled_caption))\n",
        "\n",
        "                    # Enhanced style details with NLP analysis\n",
        "                    analysis = detail.get('analysis_details', {})\n",
        "                    style_details.append(\n",
        "                        f\"Scene: {detail['scene_text']}\\n\"\n",
        "                        f\"Style Applied: {detail['style_applied']}\\n\"\n",
        "                        f\"Keywords Used: {', '.join(detail['keywords_used'])}\\n\"\n",
        "                        f\"Emotion Analysis: {analysis.get('emotion_analysis', {})}\\n\"\n",
        "                        f\"Semantic Score: {analysis.get('semantic_analysis', {})}\\n\"\n",
        "                        f\"---\"\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error formatting scene result: {str(e)}\")\n",
        "\n",
        "            yield [source_images, styled_images, \"\\n\\n\".join(style_details), \"Processing complete!\"]\n",
        "\n",
        "        except Exception as e:\n",
        "            error_message = f\"❌ Error: {str(e)}\"\n",
        "            logger.error(error_message)\n",
        "            yield [[], [], \"\", error_message]\n",
        "\n",
        "    generate_btn.click(\n",
        "        fn=wrapper_fn,\n",
        "        inputs=story_input,\n",
        "        outputs=[source_gallery, styled_gallery, style_info, status]\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ## How to Use\n",
        "    1. Enter your story in the text box\n",
        "    2. Click \"Generate Visual Story\"\n",
        "    3. Wait for the AI to process each sentence and generate images\n",
        "    4. Review the source images, stylized results, and analysis details\n",
        "\n",
        "    Note: Processing may take longer on CPU environments.\n",
        "    \"\"\")\n",
        "\n",
        "app.launch(server_name=\"0.0.0.0\", share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842,
          "referenced_widgets": [
            "87a85b04bf9f407fbe976d0cb4f44021",
            "67fb9b8bf4f64889a701af2e6668bd39",
            "1ec9c1d0a6254079b3d4837867c779f1",
            "d9a6d425f51a46ffa74e5869ac7e69a0",
            "50596aa584b049dca8e2493b3014b1b1",
            "1682daacd2f9494c91af84579aa50a90",
            "25a4c19134494f65b5502eb8b33f130f",
            "96d3cad14a1b41d7a52db5a054a5335a",
            "a514cfed85874cf0973c22a0cab92a5f",
            "ecc078d34f4142e9a5b34175539b7953",
            "11147eb24b3044e498e7518a136627a9",
            "343bc7fa4e4f4e8c861976625f522f81",
            "a2677bf345c64113a7bafaa9b9ef2fc2",
            "825a729413324dc994771e0a7f1899e3",
            "95d0752e42b24ed1ba27eec281d55a39",
            "77fb0c96ca81469aa975f6a44b6a24bb",
            "221a797f342f4f1696617d9755201d08",
            "259a355eb2fe4a72bf2526e41eb1f690",
            "23dc9ea18c094bc585efe9346300ed4b",
            "b35769e5ab0c49f6969eab6d04b327e1",
            "9e49294ec73f41e59f7f294d33ba782f",
            "ce1fed5397cf4af28af56a762b1a82c3"
          ]
        },
        "id": "1f80jNtDfGkv",
        "outputId": "f30f48fe-9dfb-406f-d335-8ddd00b67e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://5b7ae2229be4c0ba32.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5b7ae2229be4c0ba32.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87a85b04bf9f407fbe976d0cb4f44021"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "343bc7fa4e4f4e8c861976625f522f81"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}